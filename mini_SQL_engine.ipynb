{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mini_SQL_engine.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbsvsVmKqehI"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import csv\n",
        "import numpy as np\n",
        "import re\n",
        "import pprint\n",
        "import itertools\n",
        "\n",
        "# globals\n",
        "DB_DIR = \"../files/\"\n",
        "META_FILE = \"../files/metadata.txt\"\n",
        "AGGREGATE = [\"min\", \"max\", \"sum\", \"avg\", \"count\", \"distinct\"]\n",
        "RELATE_OPS = [\"<\", \">\", \"<=\", \">=\", \"=\", \"<>\"]\n",
        "LITERAL = \"<literal>\"\n",
        "\n",
        "schema = {}\n",
        "\n",
        "def errorif(x, s):\n",
        "    if x:\n",
        "        # assert not x, s\n",
        "        print(\"ERROR : {}\".format(s))\n",
        "        exit(-1)\n",
        "\n",
        "def isint(s):\n",
        "    try:\n",
        "        _ = int(s)\n",
        "        return True\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "def get_relate_op(cond):\n",
        "    if \"<=\" in cond: op = \"<=\"\n",
        "    elif \">=\" in cond: op = \">=\"\n",
        "    elif \"<>\" in cond: op = \"<>\"\n",
        "    elif \">\" in cond: op = \">\"\n",
        "    elif \"<\" in cond: op = \"<\"\n",
        "    elif \"=\" in cond: op = \"=\"\n",
        "    else : errorif(True, \"invalid condition : '{}'\".format(cond))\n",
        "\n",
        "    errorif(cond.count(op) != 1, \"invalid condition : '{}'\".format(cond))\n",
        "    l, r = cond.split(op)\n",
        "    l = l.strip()\n",
        "    r = r.strip()\n",
        "    return op, l, r\n",
        "\n",
        "\n",
        "def init_metadata():\n",
        "    with open(META_FILE, \"r\") as f:\n",
        "        contents = f.readlines()\n",
        "    contents = [t.strip() for t in contents if t.strip()]\n",
        "\n",
        "    table_name = None\n",
        "    for t in contents:\n",
        "        t = t.lower()\n",
        "        if t == \"<begin_table>\": attrs, table_name = [], None\n",
        "        elif t == \"<end_table>\": pass\n",
        "        elif not table_name: table_name, schema[t] = t, []\n",
        "        else: schema[table_name].append(t)\n",
        "\n",
        "def load_table(fname):\n",
        "    # ll = list(csv.reader(open(fname, \"r\")))\n",
        "    # return list(map(lambda x : list(map(int, x)), ll))\n",
        "    return np.genfromtxt(fname, dtype=int, delimiter=',')\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def recursion(qdict, inter_table, till_row, idx):\n",
        "    if idx == len(qdict['tables']):\n",
        "        # check conditions\n",
        "        inter_table.append(till_row)\n",
        "        return\n",
        "    for row in qdict['loaded_tables'][idx]:\n",
        "        recursion(qdict, inter_table, till_row + row[qdict['inter_cols'][idx]].tolist(), idx+1)\n",
        "def get_inter_table(qdict):\n",
        "    temp_qdict = qdict.copy()\n",
        "    qdict['loaded_tables'] = [\n",
        "        load_table(os.path.join(DB_DIR, \"{}.csv\".format(qdict['alias2tb'][t]))) for t in qdict['tables']\n",
        "    ]\n",
        "    inter_table = []\n",
        "    recursion(qdict, inter_table, [], 0)\n",
        "    inter_header = [tname+\".\"+schema[qdict['alias2tb'][tname]][tc] for tname, tcols in \\\n",
        "        zip(qdict['tables'], qdict['inter_cols']) for tc in tcols]\n",
        "    return inter_header, inter_table\n",
        "\"\"\"\n",
        "\n",
        "def get_output_table(qdict):\n",
        "    # pprint.pprint(qdict)\n",
        "    alias2tb = qdict['alias2tb']\n",
        "    inter_cols = qdict['inter_cols']\n",
        "    tables = qdict['tables']\n",
        "    conditions = qdict['conditions']\n",
        "    cond_op = qdict['cond_op']\n",
        "    proj_cols = qdict['proj_cols']\n",
        "\n",
        "    # load all tables and retain only necessary columns\n",
        "    # also decide the indexes of intermediate table columns\n",
        "    colidx = {}\n",
        "    cnt = 0\n",
        "    all_tables = []\n",
        "    for t in tables:\n",
        "        lt = load_table(os.path.join(DB_DIR, \"{}.csv\".format( alias2tb[t] )))\n",
        "\n",
        "        idxs = [schema[alias2tb[t]].index(cname) for cname in inter_cols[t]]\n",
        "        lt = lt[:, idxs]\n",
        "        all_tables.append(lt.tolist())\n",
        "\n",
        "        colidx[t] = {cname: cnt+i for i, cname in enumerate(inter_cols[t])}\n",
        "        cnt += len(inter_cols[t])\n",
        "\n",
        "    # cartesian product of all tables\n",
        "    inter_table = [[i for tup in r for i in list(tup)] for r in itertools.product(*all_tables)]\n",
        "    inter_table = np.array(inter_table)\n",
        "\n",
        "    # check for conditions and get reduced table\n",
        "    if len(conditions):\n",
        "        totake = np.ones((inter_table.shape[0],len(conditions)), dtype=bool)\n",
        "\n",
        "        for idx, (op, left, right) in enumerate(conditions):\n",
        "            cols = []\n",
        "            for tname, cname in [left, right]:\n",
        "                if tname == LITERAL: cols.append(np.full((inter_table.shape[0]), int(cname)))\n",
        "                else: cols.append(inter_table[:, colidx[tname][cname]])\n",
        "\n",
        "            if op==\"<=\": totake[:, idx] = (cols[0] <= cols[1])\n",
        "            if op==\">=\": totake[:, idx] = (cols[0] >= cols[1])\n",
        "            if op==\"<>\": totake[:, idx] = (cols[0] != cols[1])\n",
        "            if op==\"<\": totake[:, idx] = (cols[0] < cols[1])\n",
        "            if op==\">\": totake[:, idx] = (cols[0] > cols[1])\n",
        "            if op==\"=\": totake[:, idx] = (cols[0] == cols[1])\n",
        "\n",
        "        if cond_op == \" or \": final_take = (totake[:, 0] |  totake[:, 1])\n",
        "        elif cond_op == \" and \": final_take = (totake[:, 0] & totake[:, 1])\n",
        "        else: final_take = totake[:, 0]\n",
        "        inter_table = inter_table[final_take]\n",
        "\n",
        "    select_idxs = [colidx[tn][cn] for tn, cn, aggr in proj_cols]\n",
        "    inter_table = inter_table[:, select_idxs]\n",
        "\n",
        "    # process for aggregate function\n",
        "    if proj_cols[0][2]:\n",
        "        out_table = []\n",
        "        disti = False\n",
        "        for idx, (tn, cn, aggr) in enumerate(proj_cols):\n",
        "            col = inter_table[:, idx]\n",
        "            if aggr == \"min\": out_table.append(min(col))\n",
        "            elif aggr == \"max\": out_table.append(max(col))\n",
        "            elif aggr == \"sum\": out_table.append(sum(col))\n",
        "            elif aggr == \"avg\": out_table.append(sum(col)/col.shape[0])\n",
        "            elif aggr == \"count\": out_table.append(col.shape[0])\n",
        "            elif aggr == \"distinct\":\n",
        "                seen = set()\n",
        "                out_table = [x for x in col.tolist() if not (x in seen or seen.add(x) )]\n",
        "                disti = True\n",
        "            else: errorif(True, \"invalid aggregate\")\n",
        "        out_table = np.array([out_table])\n",
        "        if disti: out_table = np.array(out_table).T\n",
        "        out_header = [\"{}({}.{})\".format(aggr, tn, cn) for tn, cn, aggr in proj_cols]\n",
        "    else:\n",
        "        out_table = inter_table\n",
        "        out_header = [\"{}.{}\".format(tn, cn) for tn, cn, aggr in proj_cols]\n",
        "    return out_header, out_table.tolist()\n",
        "\n",
        "def break_query(q):\n",
        "    # check the structure of select, from and where\n",
        "    # ----------------------------------------------\n",
        "    toks = q.lower().split()\n",
        "    if toks[0] != \"select\":\n",
        "        log_error(\"only select is allowed\")\n",
        "\n",
        "    select_idx = [idx for idx, t in enumerate(toks) if t == \"select\"]\n",
        "    from_idx = [idx for idx, t in enumerate(toks) if t == \"from\"]\n",
        "    where_idx = [idx for idx, t in enumerate(toks) if t == \"where\"]\n",
        "\n",
        "    errorif((len(select_idx) != 1) or (len(from_idx) != 1) or (len(where_idx) > 1), \"invalid query\")\n",
        "    select_idx, from_idx = select_idx[0], from_idx[0]\n",
        "    where_idx = where_idx[0] if len(where_idx) == 1 else None\n",
        "    errorif(from_idx <= select_idx, \"invalid query\")\n",
        "    if where_idx: errorif(where_idx <= from_idx, \"invalid query\")\n",
        "\n",
        "    raw_cols = toks[select_idx+1:from_idx]\n",
        "    if where_idx:\n",
        "        raw_tables = toks[from_idx+1:where_idx]\n",
        "        raw_condition = toks[where_idx+1:]\n",
        "    else:\n",
        "        raw_tables = toks[from_idx+1:]\n",
        "        raw_condition = []\n",
        "\n",
        "    errorif(len(raw_tables) == 0, \"no tables after 'from'\")\n",
        "    errorif(where_idx != None and len(raw_condition) == 0, \"no conditions after 'where'\")\n",
        "    # ----------------------------------------------\n",
        "    return raw_tables, raw_cols, raw_condition\n",
        "\n",
        "def parse_tables(raw_tables):\n",
        "    # all joined tables\n",
        "    # ----------------------------------------------\n",
        "    raw_tables = \" \".join(raw_tables).split(\",\")\n",
        "    tables = []\n",
        "    alias2tb = {}\n",
        "    for rt in raw_tables:\n",
        "        t = rt.split()\n",
        "        errorif(not(len(t) == 1 or (len(t) == 3 and t[1] == \"as\")), \"invalid table spacification '{}'\".format(rt))\n",
        "        if len(t) == 1: tb_name, tb_alias = t[0], t[0]\n",
        "        else: tb_name, _, tb_alias = t\n",
        "\n",
        "        errorif(tb_name not in schema.keys(), \"no table name '{}'\".format(tb_name))\n",
        "        errorif(tb_alias in alias2tb.keys(), \"not unique table/alias '{}'\".format(tb_alias))\n",
        "\n",
        "        tables.append(tb_alias)\n",
        "        alias2tb[tb_alias] = tb_name\n",
        "    # ----------------------------------------------\n",
        "    return tables, alias2tb\n",
        "\n",
        "def parse_proj_cols(raw_cols, tables, alias2tb):\n",
        "    # projection columns : columns to output\n",
        "    # ----------------------------------------------\n",
        "    raw_cols = \"\".join(raw_cols).split(\",\")\n",
        "    proj_cols = []\n",
        "    for rc in raw_cols:\n",
        "        # match for aggregate function\n",
        "        regmatch = re.match(\"(.+)\\((.+)\\)\", rc)\n",
        "        if regmatch: aggr, rc = regmatch.groups()\n",
        "        else: aggr = None\n",
        "\n",
        "        # either one of these two : col or table.col\n",
        "        errorif(\".\" in rc and len(rc.split(\".\")) != 2, \"invalid column name '{}'\".format(rc))\n",
        "\n",
        "        # get table name and column name\n",
        "        tname = None\n",
        "        if \".\" in rc:\n",
        "            tname, cname = rc.split(\".\")\n",
        "            errorif(tname not in alias2tb.keys(), \"unknown field : '{}'\".format(rc))\n",
        "        else:\n",
        "            cname = rc\n",
        "            if cname != \"*\":\n",
        "                tname = [t for t in tables if cname in schema[alias2tb[t]]]\n",
        "                errorif(len(tname) > 1, \"not unique field : '{}'\".format(rc))\n",
        "                errorif(len(tname) == 0, \"unknown field : '{}'\".format(rc))\n",
        "                tname = tname[0]\n",
        "\n",
        "        # add all columns if *\n",
        "        if cname == \"*\":\n",
        "            errorif(aggr != None, \"can't use aggregate '{}'\".format(aggr))\n",
        "            if tname != None:\n",
        "                proj_cols.extend([(tname, c, aggr) for c in schema[alias2tb[tname]]])\n",
        "            else:\n",
        "                for t in tables:\n",
        "                    proj_cols.extend([(t, c, aggr) for c in schema[alias2tb[t]]])\n",
        "        else:\n",
        "            errorif(cname not in schema[alias2tb[tname]], \"unknown field : '{}'\".format(rc))\n",
        "            proj_cols.append((tname, cname, aggr))\n",
        "\n",
        "    # either all columns without aggregate or all columns with aggregate\n",
        "    s = [a for t, c, a in proj_cols]\n",
        "    errorif(all(s) ^ any(s), \"aggregated and nonaggregated columns are not allowed simultaneously\")\n",
        "    errorif(any([(a==\"distinct\") for a in s]) and len(s)!=1, \"distinct can only be used alone\")\n",
        "    # ----------------------------------------------\n",
        "    return proj_cols\n",
        "\n",
        "def parse_conditions(raw_condition, tables, alias2tb):\n",
        "    # parse conditions\n",
        "    # ----------------------------------------------\n",
        "    conditions = []\n",
        "    cond_op = None\n",
        "    if raw_condition:\n",
        "        raw_condition = \" \".join(raw_condition)\n",
        "\n",
        "        if \" or \" in raw_condition: cond_op = \" or \"\n",
        "        elif \" and \" in raw_condition: cond_op = \" and \"\n",
        "\n",
        "        if cond_op: raw_condition = raw_condition.split(cond_op)\n",
        "        else: raw_condition = [raw_condition]\n",
        "\n",
        "        for cond in raw_condition:\n",
        "            relate_op, left, right = get_relate_op(cond)\n",
        "            parsed_cond = [relate_op]\n",
        "            for idx, rc in enumerate([left, right]):\n",
        "                if isint(rc):\n",
        "                    parsed_cond.append((LITERAL, rc))\n",
        "                    continue\n",
        "\n",
        "                if \".\" in rc:\n",
        "                    tname, cname = rc.split(\".\")\n",
        "                else:\n",
        "                    cname = rc\n",
        "                    tname = [t for t in tables if rc in schema[alias2tb[t]]]\n",
        "                    errorif(len(tname) > 1, \"not unique field : '{}'\".format(rc))\n",
        "                    errorif(len(tname) == 0, \"unknown field : '{}'\".format(rc))\n",
        "                    tname = tname[0]\n",
        "                errorif((tname not in alias2tb.keys()) or (cname not in schema[alias2tb[tname]]),\n",
        "                    \"unknown field : '{}'\".format(rc))\n",
        "                parsed_cond.append((tname, cname))\n",
        "            conditions.append(parsed_cond)\n",
        "    # ----------------------------------------------\n",
        "    return conditions, cond_op\n",
        "\n",
        "\n",
        "def parse_query(q):\n",
        "\n",
        "    # break query\n",
        "    raw_tables, raw_cols, raw_condition = break_query(q)\n",
        "    # get tables\n",
        "    tables, alias2tb = parse_tables(raw_tables)\n",
        "    # get columns to be projected\n",
        "    proj_cols = parse_proj_cols(raw_cols, tables, alias2tb)\n",
        "    # get conditions\n",
        "    conditions, cond_op = parse_conditions(raw_condition, tables, alias2tb)\n",
        "\n",
        "    # decide all needed columns for each table\n",
        "    # ----------------------------------------------\n",
        "    inter_cols = {t : set() for t in tables}\n",
        "    for tn, cn, _ in proj_cols: inter_cols[tn].add(cn)\n",
        "    for cond in conditions:\n",
        "        for tn, cn in cond[1:]:\n",
        "            if tn == LITERAL: continue\n",
        "            inter_cols[tn].add(cn)\n",
        "\n",
        "    for t in tables: inter_cols[t] = list(inter_cols[t])\n",
        "    # ----------------------------------------------\n",
        "\n",
        "    return {\n",
        "        'tables':tables,\n",
        "        'alias2tb':alias2tb,\n",
        "        'proj_cols':proj_cols,\n",
        "        'conditions':conditions,\n",
        "        'cond_op':cond_op,\n",
        "        'inter_cols':inter_cols,\n",
        "    }\n",
        "\n",
        "\n",
        "def print_table(header, table):\n",
        "    print(\",\".join(map(str, header)))\n",
        "    for row in table:\n",
        "        print(\",\".join(map(str, row)))\n",
        "\n",
        "\n",
        "def main():\n",
        "    init_metadata()\n",
        "    if len(sys.argv) != 2:\n",
        "        print(\"ERROR : invalid args\")\n",
        "        print(\"USAGE : python {} '<sql query>'\".format(sys.argv[0]))\n",
        "        exit(-1)\n",
        "    q = sys.argv[1]\n",
        "\n",
        "    qdict = parse_query(q)\n",
        "    out_header, out_table = get_output_table(qdict)\n",
        "\n",
        "    print_table(out_header, out_table)\n",
        "    # inter_header, inter_table = get_inter_table(qdict)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}